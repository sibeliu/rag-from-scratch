{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: python script.py '<question>'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "import openai \n",
    "from os.path import join, dirname\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from environment variables\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"Please set the environment variable OPENAI_API_KEY.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Read the question from the command line\n",
    "if len(sys.argv) != 2:\n",
    "    print(\"Usage: python script.py '<question>'\")\n",
    "    sys.exit(1)\n",
    "\n",
    "path = sys.argv[1]\n",
    "question = sys.argv[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import fitz\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"Load text from a PDF file using PyMuPDF.\"\"\"\n",
    "    doc = fitz.open(file_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def chunk_text(text, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"Chunk the text using semantic chunking. Modify gradient threshold and min_chunk_size to improve results.\"\"\"\n",
    "    text_splitter = SemanticChunker(\n",
    "                OpenAIEmbeddings(), \n",
    "                breakpoint_threshold_type=\"gradient\",\n",
    "                breakpoint_threshold_amount=.94,\n",
    "                min_chunk_size=1000\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "path = 'ExampleCo - NDA - John Appleseed.pdf'\n",
    "\n",
    "# Load the PDF text\n",
    "text = load_pdf(path)\n",
    "\n",
    "# Chunk the text\n",
    "chunks = chunk_text(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the chunks for testing\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}:\\n{chunk}\\n{'-'*80}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the chunks to database: we want to be able to perform hybrid search for both vector similarity and BM25\n",
    "\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine, Column, Integer, String, LargeBinary, Float\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the SentenceTransformer model for generating embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Create a SQLite database engine\n",
    "engine = create_engine('sqlite:///text_chunks.db', echo=True)\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define the TextChunk model\n",
    "class TextChunk(Base):\n",
    "    __tablename__ = 'text_chunks'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    text = Column(String)\n",
    "    embedding = Column(LargeBinary)\n",
    "\n",
    "# Create the table\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# Create a session\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "def save_chunks_to_db(chunks):\n",
    "    \"\"\"Save text chunks and their embeddings to the database.\"\"\"\n",
    "    for chunk in chunks:\n",
    "        embedding = model.encode([chunk])[0]\n",
    "        embedding_bytes = embedding.tobytes()\n",
    "        text_chunk = TextChunk(text=chunk, embedding=embedding_bytes)\n",
    "        session.add(text_chunk)\n",
    "    session.commit()\n",
    "\n",
    "def hybrid_search(query, top_k=5):\n",
    "    \"\"\"Perform hybrid search over both vector embeddings and keywords.\"\"\"\n",
    "    # Generate the query embedding\n",
    "    query_embedding = model.encode([query])[0]\n",
    "    \n",
    "    # Fetch all chunks from the database\n",
    "    chunks = session.query(TextChunk).all()\n",
    "    \n",
    "    # Calculate cosine similarity for vector search\n",
    "    similarities = []\n",
    "    for chunk in chunks:\n",
    "        chunk_embedding = np.frombuffer(chunk.embedding, dtype=np.float32)\n",
    "        similarity = cosine_similarity([query_embedding], [chunk_embedding])[0][0]\n",
    "        similarities.append((chunk, similarity))\n",
    "    \n",
    "    # Sort by similarity (vector search)\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Perform keyword search\n",
    "    keyword_matches = [chunk for chunk, _ in similarities if query.lower() in chunk.text.lower()]\n",
    "    \n",
    "    # Combine results (hybrid search)\n",
    "    hybrid_results = keyword_matches + [chunk for chunk, _ in similarities if chunk not in keyword_matches]\n",
    "    \n",
    "    # Return top_k results\n",
    "    return hybrid_results[:top_k]\n",
    "\n",
    "\n",
    "# Save chunks to the database\n",
    "save_chunks_to_db(chunks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-01 11:14:59,086 INFO sqlalchemy.engine.Engine SELECT text_chunks.id AS text_chunks_id, text_chunks.text AS text_chunks_text, text_chunks.embedding AS text_chunks_embedding \n",
      "FROM text_chunks\n",
      "2024-11-01 11:14:59,088 INFO sqlalchemy.engine.Engine [cached since 1377s ago] ()\n",
      "Result 1:\n",
      "This Agreement shall be governed by and construed in accordance with the laws\n",
      "of the State of California without regard to the conflicts of law principles thereof.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Result 2:\n",
      "15. The Recipient shall be responsible for any breach of the provisions of this\n",
      "Agreement by the representatives of the Recipient (including, without limitation, any directors,\n",
      "officers and employees to whom Confidential Information is disclosed pursuant to Section 3). 16. This Agreement shall be governed by and construed in accordance with the laws\n",
      "of the State of California without regard to the conflicts of law principles thereof. This\n",
      "Agreement has been negotiated by both parties and shall not be strictly construed against either\n",
      "party. 17. Each party understands and agrees that, because of the unique nature of the\n",
      "Confidential Information, the Company will suffer irreparable harm if the Recipient fails to\n",
      "comply with any of its obligations under this Agreement, and monetary damages will be\n",
      "inadequate to compensate the Company for such breach. Accordingly, the Recipient agrees that\n",
      "the Company shall, in addition to any other remedies available to the Company at law or in\n",
      "equity, be entitled to injunctive relief to enforce the terms of this Agreement without posting a\n",
      "bond or other undertaking.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Result 3:\n",
      "No change, modification, extension, termination or waiver of this Agreement, or\n",
      "any of the provisions herein contained, shall be valid unless made in writing and signed by duly\n",
      "authorized representatives of the parties hereto.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Result 4:\n",
      "This Agreement shall not be construed to grant any license or other rights except\n",
      "as expressly specified herein.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Result 5:\n",
      "The Recipient may not assign this Agreement, whether by operation of law or\n",
      "otherwise, without the prior express written consent of the Company.\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform a hybrid search\n",
    "query = \"is this contract under california law\"\n",
    "results = hybrid_search(query)\n",
    "\n",
    "# Print the results\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Result {i+1}:\\n{result.text}\\n{'-'*80}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the context used is: This Agreement shall be governed by and construed in accordance with the laws\n",
      "of the State of California without regard to the conflicts of law principles thereof.\n",
      "Generated Response:\n",
      " ChatCompletionMessage(content='Yes, the contract is governed by California law. The agreement explicitly states that it shall be governed by and construed in accordance with the laws of the State of California.', role='assistant', function_call=None, tool_calls=None, refusal=None)\n"
     ]
    }
   ],
   "source": [
    "#Now answer the user question with the provided context\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def generate_response(base_prompt, user_question, context):\n",
    "    # Combine the base prompt, context, and user question into a single prompt\n",
    "    \n",
    "    user_prompt = f\"Context:\\n{context}\\n\\nUser Question: {user_question}\"\n",
    "    \n",
    "    client = OpenAI()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": base_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens=200,\n",
    "            temperature=0.2\n",
    "    )\n",
    "    return response.choices[0].message #response.choices[0].text.strip()\n",
    "\n",
    "\n",
    "# Define the base prompt\n",
    "base_prompt = \"You are a helpful assistant. Use the following context to answer the user's question.\"\n",
    "\n",
    "# Define the user's question\n",
    "user_question = \"Is this contract under california law?\"\n",
    "\n",
    "# Define the context  (taking the top 1 here for simplicity, tune for pricing/precision)\n",
    "context = results[0].text\n",
    "print (\"the context used is:\", context)\n",
    "\n",
    "# Generate the response\n",
    "response = generate_response(base_prompt, user_question, context)\n",
    "\n",
    "# Print the response\n",
    "print(\"Generated Response:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
